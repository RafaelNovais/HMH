{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRq1GXuRX1Ggf7XpHHWOCB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RafaelNovais/HMH/blob/main/MindMap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mh5kFbCkvU2Y"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1 Duck typing**\n",
        "\n",
        "means the same code can run with different types, as long as they have the right\n",
        "behaviour, which is determined at runtime.\n",
        "def hist(s):\n",
        "d = collections.defaultdict(int)\n",
        "for x in s:\n",
        "d[x] += 1\n",
        "return d\n",
        "Here, it doesn’t matter whether s is a list, set, tuple, string, or something else, as long as we\n",
        "can iterate over it. Grading: +3 for explanation, +2 for code.\n",
        "\n",
        "\n",
        "**2 -Memoisation means** (1)\n",
        "\n",
        "storing the result of every call to a function so that if it is ever called\n",
        "again with the same arguments, the result can be looked-up and returned without re-calculating\n",
        "it, (1) to save time. In order to be useful, (1) the function must be called repeatedly; there\n",
        "must be the possibility that it will be called repeatedly with the same arguments; (1) it must\n",
        "be relatively time-consuming; (1) it must be deterministic.\n",
        "\n",
        "\n",
        "**3 - Lambda x: x*0.3**\n",
        "soma_lambda = lambda numero1, numero2: numero1 + numero2  # Função soma escrita como Função Lambda\n",
        "\n",
        "**4 Supervizionada**\n",
        "\n",
        "4.1 - Regression\n",
        "Regressao e quando vc tenta prever um valor especifico um valor numerico (Preco, Dado Numerico, Idade, Metro )\n",
        "\t4.1.1 - Regressao Lienar identificar um valor de imovel Best Line\n",
        "\t\t\tMultiple Linaer\n",
        "\t\t\tPolynomial\n",
        "\n",
        "\t4.1.2 - Decison Tree  Contra Oferfiting ,  \n",
        "\t\t\tNodes\n",
        "\n",
        "\t4.1.3 - Random Forests\n",
        "\t\t\tMutiple Decision Tree\n",
        "\n",
        "\t4.1.4 - Neural Net Work\n",
        "\t\t\tInput > Hidden > Output Layer\n",
        "\n",
        "\t4.1.5 -\tAdaBoost Fraude de cartao\n",
        "\n",
        "\t4.1.6 - Gradient Boost\n",
        "\n",
        "\n",
        "4.2- Classification - Classificacao encontra a classe output discrete    ( Tem doenca ou nao tem , email e span ou nao e spam, perfil de cliente )\n",
        "\t4.2.1 - Regressao logistica   Valores de saidas binarios risco em seguradoras output 0/1, predict Probabiliiti ODDs\n",
        "\n",
        "\t4.2.2 - Suport Vector Machine - Find a Hiperline N-Dimensional space that distinctly classifies data points\n",
        "\t\tHyperplanes\n",
        "\t\tKernels\n",
        "\n",
        "\t4.2.3 - Naive Bayes\n",
        "\n",
        "\t4.2.4 - Decision Tree, Random Forest, Neural Net work but the Output is discrete\n",
        "\n",
        "\t4.2.5 - K-Near Neighbours Distance Metric\n",
        "\n",
        "\n",
        "**5 Nao Supervizionada**\n",
        "\n",
        "5.1 - Clustering - separa em grupos, Segmentation\n",
        "\t5.1.1 - K-means\n",
        "\n",
        "\t5.1.2 - Hierarchical\n",
        "\n",
        "\t5.1.3 - Mean Shift\n",
        "\n",
        "\t5.1.4 - Density-Based\n",
        "\n",
        "\n",
        "\n",
        "5.2 - Dimensionality Redunction  - Process of reduction the dimensioni of your feature set PCA - PRINCIPAL COMPONENT ANALYSIS\n",
        "\n",
        "\t5.2.1 - Feature Elimination\n",
        "\n",
        "\t5.2.2 - Feature Extraction\n",
        "\n",
        "\n",
        "\n",
        "**6 - Verifica dado/ Normalization**\n",
        "\t6.1 - Dados nulos ou vazio\n",
        "\n",
        "\t6.2 - Kbest pontua as melhores features\n",
        "\t\t6.2.1 - Predictive  Useful information when estimating correct target\n",
        "\t\t6.2.2 - Interacting Useful information only when considered in conjuction with other features\n",
        "\t\t6.2.3 - Redundant \tStrong correlation with another feature\n",
        "\t\t6.2.4 - Irrelevant \tNot important\n",
        "\n",
        "\n",
        "\tVerifica correlacao entre dados\n",
        "\tRescale all dimensions independently\n",
        "\n",
        "\n",
        "\n",
        "**7 - Similarity-based Learning**\n",
        "\n",
        "\t7.1 Metric\n",
        "\t\tEuclidian\n",
        "\t\tManhttan  - Cheaper nor necessary squares Large dataset\n",
        "\t\tMinkoeski -  Many distance metric\n",
        "\n",
        "\t7.2 Cosine Similarity\n",
        "\t\tIndex may be used to measure the similarity of two instances CONTINUOUS ATTRIBUTES\n",
        "\t\tINNER ANGLE BETWEN 2 VECTOR\n",
        "\n",
        "\n",
        "\n",
        "**8 - hypothesis language,overfitting, underfitting and noise**\n",
        "\n",
        "\n",
        "**9 - Learning Algorithms**\n",
        "\n",
        "\t9.1 - Lazy - KNN\n",
        "\t\tLearning from your neighbors / Simply /Training Data / Test Tuple\n",
        "\t\tFast time training but Slow time in predicting\n",
        "\t\tAccuracy\n",
        "\n",
        "\t9.2 - Eager - Linear Regression, Logistic Regression, Support Vector Machines, Decision Trees, and Artificial Neural Networks.\n",
        "\t\tContructs a classification model\n",
        "\t\tbuild a model based\n",
        "\t\tSlow time training but Fast time predicting  \n",
        "\n",
        "\n",
        "**10 - curse of dimensionality**\n",
        "\n",
        "\n",
        "**11- Reinforcement Learning/MDPs Aprendizagem (Carro Autonomo )**\n",
        "\n",
        "\tAmbiente + Agente + Acao\n",
        "\tEquacao de bellman\n",
        "\n",
        "\t11.1 - Markov Decision Process, Previsao do Tempo (B - A - B = 0.18 ou B - B -B = 0.16)\n",
        "\t\t\tA - A = 0.7\n",
        "\t\t\tA - B = 0.3\n",
        "\t\t\tB - B = 0.4\n",
        "\t\t\tB - A = 0.6\n",
        "\t11.2 - Q-Learning Algorithm,\n",
        "\t11.3 - Reward-Based Learning Reforço Recompensa Positiva e Negativa\n",
        "\n",
        "\n",
        "**12 - training, testing and validation data sets,cross-validation**\n",
        "\n",
        "\n",
        "**13- compute performance measures, learning curves and ROC graphs**\n",
        "\n",
        "\n",
        "**14- Feature Scaling, Kbest, feature**\n",
        "\n",
        "\n",
        "**15- prior and conditional probability, axioms of probability and Bayes' rule**\n",
        "\tBayes’ Rule: Example\n",
        "\tNaïve Bayes Classifier\n",
        "\n",
        "\n",
        "**16 - Variable**\n",
        "\t16.1 - Quantitativa (Numero)\n",
        "\t\t16.1.1 - Discreta - Numero Natural (inteiro, 0,5 nao faz sentido) Numero de filhos\n",
        "\t\t16.1.2 - Continua - Numero Decimal (Float 0,5 FAZ Sentido) Renda, dinheiro\n",
        "\n",
        "\t16.2 - Qualitativa - (Palavra)\n",
        "\t\t16.2.1 - Ordinal - Uma Ordenacao Escolaridade melhor e pior\n",
        "\t\t16.2.2 - Nominal - NAO tem ordem - Tipo Sange\n"
      ],
      "metadata": {
        "id": "SEPxBWX5vWR6"
      }
    }
  ]
}